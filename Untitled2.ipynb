{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V79YmN9Kuddz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is a parameter?\n",
        "  - A parameter is an internal variable within a model that is learned from the data during training, and its values are adjusted to improve the model's performance. These parameters are not set manually beforehand but are determined by the model itself during the learning process.\n",
        "\n",
        "2. What is correlation?\n",
        "   What does negative correlation mean?\n",
        "  - In machine learning, correlation describes the extent to which two or more variables change together. It's a statistical measure that quantifies the strength and direction of their relationship, indicating how closely they move in sync. Correlation doesn't imply cause-and-effect, but it reveals how variables are related, which is crucial for building and interpreting machine learning models.\n",
        "\n",
        "     A negative correlation, also known as an inverse correlation, describes a relationship between two variables where an increase in one variable is associated with a decrease in the other. In other words, they move in opposite directions.\n",
        "\n",
        "3. Define Machine Learning. What are the main components in Machine Learning?\n",
        " - Machine learning (ML) is a subset of artificial intelligence (AI) that enables computers to learn from data without being explicitly programmed. It involves algorithms and models that can improve with experience and data exposure, allowing them to make predictions and decisions autonomously. The main components of machine learning include data, algorithms, models, and predictions.\n",
        "\n",
        "     Data:\n",
        "     \n",
        "     This is the raw material for machine learning. It can be in various formats like text, images, or numerical datasets.\n",
        "\n",
        "     Algorithms:\n",
        "     \n",
        "     These are the sets of instructions that enable the system to learn from the data.\n",
        "     \n",
        "     Models:\n",
        "\n",
        "     These are the representations of the patterns and relationships learned from the data. They are trained using algorithms to make predictions or decisions.\n",
        "     \n",
        "     Predictions:\n",
        "\n",
        "     Machine learning models are used to make predictions or decisions based on the learned patterns.\n",
        "\n",
        "4. How does loss value help in determining whether the model is good or not?\n",
        "  - A model's loss value indicates how well it performs by measuring the difference between its predictions and the actual values. Lower loss values generally signify better performance, as they indicate the model's predictions are closer to the true values.\n",
        "\n",
        "5. What are continuous and categorical variables?\n",
        "  - In statistics and data analysis, variables can be broadly classified as either continuous or categorical. Continuous variables can take on any value within a specified range, while categorical variables represent distinct categories or groups.\n",
        "\n",
        "     Continuous Variables:\n",
        "   \n",
        "   \n",
        "   Definition: These variables can have any value within a range, and the difference between two values is meaningful.\n",
        "   \n",
        "   Examples: Height, weight, temperature, income, or time.\n",
        "   \n",
        "   Characteristics: They are typically measured and can be expressed in numerical terms with decimal values.\n",
        "\n",
        "   Categorical Variables:\n",
        "   \n",
        "     Definition:\n",
        "     These variables represent categories or groups, and each observation belongs to only one category.\n",
        "\n",
        "     Examples:\n",
        "     Gender (male/female), color (red/blue/green), or type of car (sedan/SUV/truck).\n",
        "\n",
        "     Characteristics:\n",
        "     They are often nominal (no inherent order) or ordinal (categories have a meaningful order).\n",
        "    \n",
        "6. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "  - Handling categorical variables in machine learning involves converting them into a numerical format that algorithms can understand. Common techniques include one-hot encoding, ordinal encoding, and target encoding, among others. The choice of technique depends on the nature of the data and the algorithm being used.\n",
        "\n",
        "     One-Hot Encoding:\n",
        "     \n",
        "     This method creates a binary column for each category, where 1 represents the presence of that category and 0 represents its absence. It's useful when categories are nominal (no inherent order).\n",
        "\n",
        "     Ordinal Encoding:\n",
        "     \n",
        "     This approach assigns unique integer values to each category, preserving any natural order among the categories. For example, \"Never\" (0) < \"Rarely\" (1) < \"Most days\" (2) < \"Every day\" (3).\n",
        "\n",
        "     Target Encoding (Mean Encoding):\n",
        "     \n",
        "     This technique replaces each category with the mean of the target variable for that category. It can be useful when there's a relationship between the categorical feature and the target.\n",
        "\n",
        "7. What do you mean by training and testing a dataset?\n",
        " - In the context of machine learning, \"training\" a dataset means using a portion of your data to teach a model how to make predictions. \"Testing\" a dataset, on the other hand, involves using a separate portion of data to evaluate how well the trained model generalizes to unseen data.\n",
        "\n",
        "8. What is sklearn.preprocessing?\n",
        " - sklearn.preprocessing is a module in the scikit-learn library that provides a variety of utility functions and transformer classes. These tools are used to change raw feature vectors into a representation that is more suitable for downstream machine learning estimators.\n",
        "\n",
        "9. What is a Test set?\n",
        " - A test set is a portion of a dataset used to evaluate the performance of a machine learning model after it has been trained. It's separate from the training data and provides an unbiased assessment of how well the model generalizes to new, unseen data.\n",
        "\n",
        "10. How do we split data for model fitting (training and testing) in Python?\n",
        "How do you approach a Machine Learning problem?\n",
        " - In Python, data is typically split into training and testing sets using train_test_split from scikit-learn. A common approach is to use 80% for training and 20% for testing, though this can vary. When approaching a machine learning problem, it's crucial to understand the data, choose an appropriate model, evaluate its performance, and consider potential improvements.\n",
        "\n",
        "11. Why do we have to perform EDA before fitting a model to the data?\n",
        " - Exploratory Data Analysis (EDA) before model fitting is crucial for several reasons. It allows you to understand the data's structure, identify patterns, and detect potential issues like errors, outliers, and relationships between variables. This knowledge helps you make informed decisions about feature engineering, model selection, and ultimately leads to better model performance.\n",
        "\n",
        "12. What is correlation?\n",
        "  - In machine learning, correlation describes the extent to which two or more variables change together. It's a statistical measure that quantifies the strength and direction of their relationship, indicating how closely they move in sync. Correlation doesn't imply cause-and-effect, but it reveals how variables are related, which is crucial for building and interpreting machine learning models.\n",
        "\n",
        "13. What does negative correlation mean?\n",
        "  - A negative correlation, also known as an inverse correlation, describes a relationship between two variables where an increase in one variable is associated with a decrease in the other. In other words, they move in opposite directions.\n",
        "\n",
        "14. How can you find correlation between variables in Python?\n",
        "   - 1. Using Pandas:\n",
        "The .corr() method on a Pandas DataFrame calculates the correlation matrix.\n",
        "By default, it uses the Pearson correlation coefficient, but you can specify other methods like 'spearman' or 'kendall'.\n",
        "\n",
        "     2. Using NumPy:\n",
        "The np.corrcoef() function calculates the correlation matrix and Example.\n",
        "\n",
        "     3. Using SciPy:\n",
        "The scipy.stats.pearsonr() function calculates the Pearson correlation coefficient and the p-value between two variables.\n",
        "Other functions like scipy.stats.spearmanr() and scipy.stats.kendalltau() calculate Spearman's rank correlation and Kendall's Tau, respectively.\n",
        "\n",
        "15. What is causation? Explain difference between correlation and causation with an example.\n",
        "  - Causation means one event directly causes another, while correlation indicates a relationship between two events without implying one causes the other. Shiksha explains that causation always implies correlation, meaning if one event causes another, there's a relationship between them, but the reverse isn't true. For instance, if you strike a billiard ball with a cue stick, the cue stick hitting the ball causes it to move. However, if you observe that people who exercise more tend to be the people who get skin cancer, this doesn't mean exercise causes skin cancer. Instead, it's likely that both exercise and skin cancer are related to a third factor, such as increased exposure to sunlight.\n",
        "\n",
        "16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "  - An optimizer is an algorithm that adjusts a model's parameters (like weights and biases) during training to minimize the loss function, ultimately improving the model's accuracy. Different optimizers employ distinct strategies for this adjustment, such as gradient descent, stochastic gradient descent, or adaptive gradient algorithms.\n",
        "\n",
        "17. What is sklearn.linear_model ?\n",
        "  - sklearn.linear_model is a module in the scikit-learn (sklearn) library in Python that provides various methods for linear modeling. Linear models are used to describe the relationship between a dependent variable and one or more independent variables.\n",
        "\n",
        "18. What does model.fit() do? What arguments must be given?\n",
        "  - The model.fit() function in machine learning frameworks like TensorFlow and scikit-learn is used to train a model on a given dataset. It adjusts the model's internal parameters (weights and biases) to minimize a loss function, effectively learning patterns in the data.\n",
        "\n",
        "19. What does model.predict() do? What arguments must be given?\n",
        "  - model. predict() is used to generate predictions from the trained model based on new input data. It does not require true labels and does not compute any metrics.\n",
        "\n",
        "20. What are continuous and categorical variables?\n",
        "  - In statistics and data analysis, variables can be broadly classified as either continuous or categorical. Continuous variables can take on any value within a specified range, while categorical variables represent distinct categories or groups.\n",
        "\n",
        "21. What is feature scaling? How does it help in Machine Learning?\n",
        "  - Feature scaling is a pre-processing step in machine learning that transforms numerical features to a common scale, ensuring they all contribute equally to the model. This is crucial because many algorithms are sensitive to the scale of input data, and scaling helps to prevent features with larger ranges from dominating the learning process.\n",
        "\n",
        "22. How do we perform scaling in Python?\n",
        "   - Scaling in Python involves transforming numerical data to a specific range, which is a crucial step in data preprocessing for machine learning. It is done to ensure that all features contribute equally to the model and to improve the performance of algorithms. Here are the common scaling techniques:\n",
        "     1. Standardization:\n",
        "\n",
        "     It centers the data around the mean with a unit standard deviation.\n",
        "It is useful when data is normally distributed.\n",
        "Formula: z = (x - u) / s, where x is the data point, u is the mean, and s is the standard deviation.\n",
        "\n",
        "     from sklearn.preprocessing import StandardScaler\n",
        "     scaler = StandardScaler()\n",
        "     scaled_data = scaler.fit_transform(data)  \n",
        "\n",
        "     2. Normalization (Min-Max Scaling):\n",
        "     \n",
        "     It scales the data to a specific range, usually between 0 and 1.\n",
        "     It is useful when data does not follow a normal distribution.\n",
        "     Formula: x_scaled = (x - x_min) / (x_max - x_min).\n",
        "     Python implementation:\n",
        "     Python\n",
        "\n",
        "     from sklearn.preprocessing import MinMaxScaler\n",
        "     scaler = MinMaxScaler()\n",
        "     scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "23. What is sklearn.preprocessing?\n",
        "  - sklearn.preprocessing is a module in the scikit-learn library that provides a variety of utility functions and transformer classes. These tools are used to change raw feature vectors into a representation that is more suitable for downstream machine learning estimators.\n",
        "\n",
        "  Key functions of sklearn.preprocessing:\n",
        "\n",
        "   Data Scaling: This involves transforming numerical data to a specific range or distribution. Common methods include:\n",
        "  \n",
        "     StandardScaler: Standardizes features by removing the mean and scaling to unit variance.\n",
        "    \n",
        "     MinMaxScaler: Scales features to a given range, often between 0 and 1.\n",
        "\n",
        "     RobustScaler: Scales features using statistics that are robust to outliers, such as the median and interquartile range.\n",
        "\n",
        "24. How do we split data for model fitting (training and testing) in Python?\n",
        "  - In Python, data is typically split into training and testing sets using the train_test_split function from the sklearn.model_selection module. This function randomly divides the data into two subsets: a training set used to train the machine learning model, and a testing set used to evaluate its performance on unseen data.\n",
        "\n",
        "25. Explain data encoding?\n",
        "  - Data encoding is the process of converting information from one form to another, often for efficient transmission, storage, or analysis. It essentially involves transforming data into a specific format that can be easily processed or understood by computers or other systems."
      ],
      "metadata": {
        "id": "Rj_syehAuhSo"
      }
    }
  ]
}